{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class 04 - Text Classification II.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpDKjrLc5AV84VgtH4KlpC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmbanda/CSC8980_NLP_Spring2021/blob/main/Class_04_Text_Classification_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlAUleqcJR2U"
      },
      "source": [
        "# **Class 04 - Text Classification II**\r\n",
        "\r\n",
        "In this class we will go over code examples that use the clasic 20 newsgroups dataset (http://qwone.com/~jason/20Newsgroups/) that can be utilized via scikit-learn. \r\n",
        "\r\n",
        "In this notebook we will cover using scikit-learn to pre-process text (Bag of Words and TF-IDF) and classify text using Naive Bayes, Perceptron, Logistic Regresion, and Decision Trees.\r\n",
        "\r\n",
        "There are some practice excercises at the end of this lesson that are HIGLY recommended to be done in order to get a better understanding of this code and the text classification part of this class.\r\n",
        "\r\n",
        "**Disclaimer:** All the code provided in this and the other Colab notebooks provided during the class, is fair game to re-use for assignments, exams, and your project. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWNh-VbNLrbB"
      },
      "source": [
        "The following lines of code setup our ploting environment using matplotlib and seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSSiKqIU9Wh9"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5dBXnhIgViBu"
      },
      "source": [
        "## Multinomial Naive Bayes\n",
        "\n",
        "In multinomial Naive Bayes, where the features are assumed to be generated from a simple multinomial distribution.\n",
        "The multinomial distribution describes the probability of observing counts among a number of categories, and thus multinomial naive Bayes is most appropriate for features that represent counts or count rates. The algorithm model the data distribuiton with a best-fit multinomial distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "HwHSsiZRViBu"
      },
      "source": [
        "One place where multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified.\n",
        "In the following examples, we will use data from the 20 Newsgroups corpus to show how we might classify these short documents into categories.\n",
        "\n",
        "Let's download the data and take a look at the target names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KAonIo1YViBu"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "data = fetch_20newsgroups()\n",
        "data.target_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uwTrNcsIViBw"
      },
      "source": [
        "For simplicity here, we will select just a two of these categories, and download the training and testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "klCIgwI2fUoM"
      },
      "source": [
        "categories = ['rec.autos','comp.graphics']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ppMV6n7gViBy"
      },
      "source": [
        "Here is a representative entry from the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vZ4rLyFKViBy"
      },
      "source": [
        "print(train.data[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Y09f-32IViB0"
      },
      "source": [
        "### Bag-of-words featurization\n",
        "\n",
        "In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers.\n",
        "For this we will use the bag of words approach. This is called ``CountVectorizer`` in scikit-learn. Then we will create a pipeline that attaches it to a multinomial naive Bayes classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "R6b72OAxViB1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "model = make_pipeline(CountVectorizer(), MultinomialNB())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGjOggJxSHn8"
      },
      "source": [
        "After we create the pipeline, we then train the model using the training data (``train.data``) and the target labels (``train.target``). After the model is trained, we will use it to predict the labels of the test data (``test.data``). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "j86mym91ViB3"
      },
      "source": [
        "model.fit(train.data, train.target)\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "BsjKgkVPViB4"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator.\n",
        "For example, here is the confusion matrix between the true and predicted labels for the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "aDcVLOFmViB4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfwMgHajTuUU"
      },
      "source": [
        "While the confusion matrix shows us the class based performance, we are now going to look at additional metrics to determine the actual performance of the algorithm. Remember that in the slides for this lecture we further discused what each of these mean. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWioirwlP-yo"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8GPYWaZWViB6"
      },
      "source": [
        "Evidently, even this very simple classifier can successfully separate graphics talk from car talk.\n",
        "\n",
        "The very cool thing here is that we now have the tools to determine the category for *any* string, using the ``predict()`` method of this pipeline.\n",
        "Here's a quick utility function that will return the prediction for a single string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mD1YUsFyViB6"
      },
      "source": [
        "def predict_category(s, train=train, model=model):\n",
        "    pred = model.predict([s])\n",
        "    return train.target_names[pred[0]]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Wop-gabLViB8"
      },
      "source": [
        "predict_category('tired of unix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "43rTrzfrViB_"
      },
      "source": [
        "predict_category('need new brakes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Bvt9aChqViCD"
      },
      "source": [
        "Remember that this is nothing more sophisticated than a simple probability model for the (weighted) frequency of each word in the string; nevertheless, the result is striking.\n",
        "Even a very naive algorithm, when used carefully and trained on a large set of high-dimensional data, can be surprisingly effective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "pplHj8s0RCJt"
      },
      "source": [
        "### TF-IDF featurization\n",
        "\n",
        "Previously we used ``CountVectorizer`` or the Bag-of-words approach to convert each string into a vector of numbers.\n",
        "Now we will use the TF-IDF (term frequency–inverse document frequency) vectorizer to create a pipeline that attaches it to a multinomial naive Bayes classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ST0YyVz9RCJ_"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sda504ZUVoOv"
      },
      "source": [
        "After we create the pipeline, we then train the model using the training data (``train.data``) and the target labels (``train.target``). After the model is trained, we will use it to predict the labels of the test data (``test.data``). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "huEc1O3UVoPF"
      },
      "source": [
        "model.fit(train.data, train.target)\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "2Htm8R7nVoPH"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator.\n",
        "For example, here is the confusion matrix between the true and predicted labels for the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gpFQTjLjVoPH"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOSAPoDkVoPJ"
      },
      "source": [
        "While the confusion matrix shows us the class based performance, we are now going to look at additional metrics to determine the actual performance of the algorithm. Remember that in the slides for this lecture we further discused what each of these mean. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gXz_LpDVoPJ"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEikuQmGmUBG"
      },
      "source": [
        "## **Perceptron**\r\n",
        "\r\n",
        "As a different option to Naive Bayes, the Perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yes_qUwgXwL"
      },
      "source": [
        "### Bag-of-words featurization\r\n",
        "\r\n",
        "Here we will start using a bag-of-words featurization and the Perceptron classifier via a pipeline. We will ommit some of the same details that are discussed in the previous section as the code is the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9-Um9bxmBSr"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\r\n",
        "model = make_pipeline(CountVectorizer(), Perceptron())\r\n",
        "model.fit(train.data, train.target)\r\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i4MJIWLmQz-"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "x2QGoejimRqK"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa5wRs2-mRqM"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDllkkQKg-UV"
      },
      "source": [
        "### TF-IDF featurization\r\n",
        "Previously we used ``CountVectorizer`` or the Bag-of-words approach to convert each string into a vector of numbers.\r\n",
        "Now we will use the TF-IDF (term frequency–inverse document frequency) vectorizer to create a pipeline that attaches it to a multinomial perceptron classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z9jYmWdhYm8"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\r\n",
        "model = make_pipeline(TfidfVectorizer(), Perceptron())\r\n",
        "model.fit(train.data, train.target)\r\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tyjPz-LhYnJ"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "QF-mWhtchYnJ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsGbvoorhYnL"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw6Eh0OSm3au"
      },
      "source": [
        "## **Logistic Regression**\r\n",
        "\r\n",
        "Logistic regression is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1, with a sum of one.\r\n",
        "\r\n",
        "Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled \"0\" and \"1\". In the logistic model, the log-odds (the logarithm of the odds) for the value labeled \"1\" is a linear combination of one or more independent variables (\"predictors\"); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). The corresponding probability of the value labeled \"1\" can vary between 0 (certainly the value \"0\") and 1 (certainly the value \"1\"), hence the labeling; the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc0U1mDLiYQa"
      },
      "source": [
        "### Bag-of-words featurization\r\n",
        "\r\n",
        "Here we will start using a bag-of-words featurization and the Logistic Regression classifier via a pipeline. We will ommit some of the same details that are discussed in the previous section as the code is the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOnnxjINm3av"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "model = make_pipeline(CountVectorizer(), LogisticRegression())\r\n",
        "model.fit(train.data, train.target)\r\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKExbhRGm3aw"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ffwav52Hm3ax"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UymnB4R7m3ax"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhm46pi2xfAX"
      },
      "source": [
        "### TF-IDF featurization\r\n",
        "Previously we used ``CountVectorizer`` or the Bag-of-words approach to convert each string into a vector of numbers.\r\n",
        "Now we will use the TF-IDF (term frequency–inverse document frequency) vectorizer to create a pipeline that attaches it to a multinomial perceptron classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz18sDMkxfAs"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\r\n",
        "model.fit(train.data, train.target)\r\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A43Fj723xfAt"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tN3ryGElxfAt"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l551YKTPxfAv"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CIDuk3bnlMK"
      },
      "source": [
        "## Bonus: Decision Tree\r\n",
        "\r\n",
        "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.\r\n",
        "\r\n",
        "Some advantages of decision trees are:\r\n",
        "\r\n",
        "* Simple to understand and to interpret. Trees can be visualised.\r\n",
        "\r\n",
        "* Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.\r\n",
        "\r\n",
        "* The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.\r\n",
        "\r\n",
        "* Able to handle both numerical and categorical data. However scikit-learn implementation does not support categorical variables for now. Other techniques are usually specialised in analysing datasets that have only one type of variable. See algorithms for more information.\r\n",
        "\r\n",
        "The disadvantages of decision trees include:\r\n",
        "\r\n",
        "* Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting. Mechanisms such as pruning, setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.\r\n",
        "\r\n",
        "* Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated by using decision trees within an ensemble.\r\n",
        "\r\n",
        "* Predictions of decision trees are neither smooth nor continuous, but piecewise constant approximations as seen in the above figure. Therefore, they are not good at extrapolation.\r\n",
        "\r\n",
        "* Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiUPSkkxw1zo"
      },
      "source": [
        "Here we will start using a bag-of-words featurization and the Decision Tree classifier via a pipeline. We will ommit some of the same details that are discussed in the previous section as the code is the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3nlGeyQnlMR"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "model = make_pipeline(CountVectorizer(), DecisionTreeClassifier())\r\n",
        "model.fit(train.data, train.target)\r\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYozokIOnlMS"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Mk8TbtPInlMT"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O15mvgN1nlMU"
      },
      "source": [
        "print('Accuracy:', sklearn.metrics.accuracy_score(test.target,labels))\n",
        "print('Precision:', sklearn.metrics.precision_score(test.target,labels))\n",
        "print('Recall:', sklearn.metrics.recall_score(test.target,labels))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels, test.target, average='macro'))\n",
        "print('Mean Absolute Error:', sklearn.metrics.mean_absolute_error(test.target,labels))\n",
        "print('Mean Squared Error:', sklearn.metrics.mean_squared_error(test.target, labels))  \n",
        "print('Root Mean Squared Error:', np.sqrt(sklearn.metrics.mean_squared_error(test.target, labels)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvcVReXqyiwQ"
      },
      "source": [
        "# Recommended Excercises\r\n",
        "\r\n",
        "1) So far we have only classified two classes, try classifiying 3 or more classes with the same code (some classifers might need some adjustments). \r\n",
        "\r\n",
        "2) We have tried 3 classification algorithms, try more like SVM, Random Forests. \r\n",
        "\r\n",
        "3) The 20 news groups data comes already split in a training and a testing set. Practice splitting the data using ``train_test_split``. \r\n",
        "\r\n",
        "4) We have evaluated 3 algorithms using 2 different featurization schemes, leading to a total of 6 algorithms to evaluate. Practice comparing their performance metrics side by side. "
      ]
    }
  ]
}